{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we're going to forecast the number of bikes in 5 bike stations from the city of Toulouse.\n",
    "We'll do so by using sail's river wrapper.\n",
    "\n",
    "This tutorial is based on rivers' own example: https://riverml.xyz/dev/examples/bike-sharing-forecasting/.\n",
    "Different from river's tutorial, we will avoid using the function evaluate.progressive_val_score.\n",
    "We will do so by controlling our self the training and evaluating loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from river import datasets, metrics, optim, stats\n",
    "from sail.transformers.river.feature_extraction import TargetAgg\n",
    "from sail.models.river.linear_model import LinearRegression\n",
    "from sail.transformers.river.preprocessing import StandardScaler\n",
    "from sail.transformers.river.compose import Select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.Bikes()\n",
    "x, y = [], []\n",
    "for data, label in dataset:\n",
    "    x.append(data)\n",
    "    y.append(label)\n",
    "\n",
    "df = pd.DataFrame(x)\n",
    "df[\"target\"] = y\n",
    "\n",
    "X = df.drop([\"description\",\"target\"], axis=1)\n",
    "y = df[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SAIL transformers and start incremental training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE after 0 iterations 0.0\n",
      "MAE after 20000 iterations [4.91369848]\n",
      "MAE after 40000 iterations [5.33356474]\n",
      "MAE after 60000 iterations [5.33099467]\n",
      "MAE after 80000 iterations [5.39232983]\n",
      "MAE after 100000 iterations [5.42310781]\n",
      "MAE after 120000 iterations [5.54129902]\n",
      "MAE after 140000 iterations [5.61305014]\n",
      "MAE after 160000 iterations [5.62248674]\n",
      "MAE after 180000 iterations [5.5678413]\n",
      "Finally, MAE: [5.56392979]\n"
     ]
    }
   ],
   "source": [
    "select = Select(['clouds', 'humidity', 'pressure', 'temperature', 'wind'])\n",
    "scaler = StandardScaler()\n",
    "model = LinearRegression(optimizer=optim.SGD(0.001))\n",
    "\n",
    "metric = metrics.MAE()\n",
    "\n",
    "batch_size = 1\n",
    "for start in range(0, X.shape[0], batch_size):\n",
    "    end = start + batch_size\n",
    "    X_train = X.iloc[start:end]\n",
    "    y_train = y.iloc[start:end]\n",
    "\n",
    "    if start > 0:\n",
    "        # Predicting\n",
    "        X_train_predict = X_train.copy()\n",
    "        X_train_predict = select.transform(X_train_predict)\n",
    "        X_train_predict = scaler.transform(X_train_predict)\n",
    "        yhat = model.predict(X_train_predict)\n",
    "\n",
    "        # Update the metric\n",
    "        metric.update(y_train.to_numpy(), yhat)\n",
    "\n",
    "    # Partially fitting the model\n",
    "    X_train = select.partial_fit_transform(X_train)\n",
    "    X_train = scaler.partial_fit_transform(X_train)\n",
    "    model.partial_fit(X_train, y_train)\n",
    "\n",
    "    if start % 20000 == 0:\n",
    "        print(\"MAE after\", start, \"iterations\", metric.get())\n",
    "\n",
    "print(\"Finally, MAE:\", metric.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a new SAIL transformer: TargetAgg and restart incremental training\n",
    "\n",
    "For each station we can look at the average number of bikes per hour. To do so we first have to extract the hour from the moment field. We can then use a TargetAgg to aggregate the values of the target.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"hour\"] = df.moment.dt.hour\n",
    "\n",
    "X = df.drop([\"moment\", \"description\",\"target\"], axis=1)\n",
    "y = df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE after 0 iterations 0.0\n",
      "MAE after 20000 iterations [3.69599632]\n",
      "MAE after 40000 iterations [3.81656079]\n",
      "MAE after 60000 iterations [3.83577123]\n",
      "MAE after 80000 iterations [3.90303467]\n",
      "MAE after 100000 iterations [3.88279632]\n",
      "MAE after 120000 iterations [3.91873956]\n",
      "MAE after 140000 iterations [3.97662073]\n",
      "MAE after 160000 iterations [3.94625184]\n",
      "MAE after 180000 iterations [3.93115752]\n",
      "Finally, MAE: [3.93017217]\n"
     ]
    }
   ],
   "source": [
    "metric = metrics.MAE()\n",
    "\n",
    "agg = TargetAgg(\n",
    "    by=[\"station\", \"hour\"],\n",
    "    how=stats.Mean(),\n",
    ")\n",
    "scaler = StandardScaler()\n",
    "model = LinearRegression(optimizer=optim.SGD(0.001))\n",
    "\n",
    "batch_size = 1\n",
    "for start in range(0, X.shape[0], batch_size):\n",
    "    end = start + batch_size\n",
    "    X_train = X.iloc[start:end]\n",
    "    y_train = y.iloc[start:end]\n",
    "    \n",
    "    if start > 0:\n",
    "        X_train_predict = X_train.copy()\n",
    "        X_train_predict.insert(0, \"agg\", agg.transform(X_train_predict), True)\n",
    "        X_train_predict = X_train_predict.drop([\"station\", \"hour\"], axis=1)\n",
    "        X_train_predict = scaler.transform(X_train_predict)\n",
    "\n",
    "        # Predicting\n",
    "        yhat = model.predict(X_train_predict)\n",
    "\n",
    "        # Update the metric\n",
    "        metric.update(y_train.to_numpy(), yhat)\n",
    "\n",
    "    X_train.insert(0, \"agg\", agg.partial_fit_transform(X_train, y_train), True)\n",
    "    X_train = X_train.drop([\"station\", \"hour\"], axis=1)\n",
    "    X_train = scaler.partial_fit_transform(X_train, y_train)\n",
    "    \n",
    "    # Partially fitting the model\n",
    "    model.partial_fit(X_train, y_train)\n",
    "\n",
    "    if start % 20000 == 0:\n",
    "        print(\"MAE after\", start, \"iterations\", metric.get())\n",
    "\n",
    "print(\"Finally, MAE:\", metric.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model have improved considerably by adding the average number of bikes.\n",
    "However, in real life scenarios we will not be able to update the average number of bikes immediately.\n",
    "\n",
    "Instead, we will have to wait for some time before having that true values.\n",
    "\n",
    "River's evaluate.progressive_val_score allows you to simulate this real life scenarios by adding a \"delay\". For more information: https://riverml.xyz/dev/api/stream/simulate-qa/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sail",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
