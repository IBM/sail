{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a20ef46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation for Hedge Backpropagation Feed Forward Network for Classification\n",
    "# Original code in Theano https://github.com/LIBOL/ODL\n",
    "# Paper https://www.ijcai.org/proceedings/2018/369\n",
    "#\n",
    "# By Carlos Muniz Cuza and Jonas Brusokas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "011c86ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sail.models.torch.onn_hbp import ONNHBPClassifier, _ONNHBPModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.utils import gen_batches\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1. Create dataset for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_data_points = 40\n",
    "n_features = 15\n",
    "n_classes = 5\n",
    "\n",
    "X, y = make_classification(n_samples=n_data_points,\n",
    "                           n_features=n_features,\n",
    "                           n_informative=n_classes,\n",
    "                           random_state=0,\n",
    "                           n_classes=n_classes,\n",
    "                           n_clusters_per_class=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aade475",
   "metadata": {},
   "source": [
    "### 2. Import and check that the model works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32738ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1721, 0.2268, 0.2109, 0.1938, 0.1964],\n",
      "        [0.1458, 0.2603, 0.2098, 0.1916, 0.1926],\n",
      "        [0.1701, 0.2274, 0.2360, 0.1990, 0.1674],\n",
      "        [0.1733, 0.2240, 0.2286, 0.1826, 0.1915],\n",
      "        [0.1572, 0.2496, 0.2007, 0.1850, 0.2075],\n",
      "        [0.1709, 0.2222, 0.1919, 0.2251, 0.1898],\n",
      "        [0.1546, 0.2483, 0.2395, 0.1720, 0.1856],\n",
      "        [0.1699, 0.2345, 0.2159, 0.1945, 0.1852],\n",
      "        [0.1695, 0.2266, 0.1980, 0.2127, 0.1933],\n",
      "        [0.1941, 0.2117, 0.2136, 0.1689, 0.2117],\n",
      "        [0.1774, 0.2052, 0.1903, 0.2231, 0.2039],\n",
      "        [0.1739, 0.2297, 0.2302, 0.1814, 0.1848],\n",
      "        [0.1877, 0.2086, 0.2031, 0.1998, 0.2008],\n",
      "        [0.1855, 0.2039, 0.2237, 0.2099, 0.1770],\n",
      "        [0.1718, 0.2304, 0.2106, 0.1862, 0.2010],\n",
      "        [0.1630, 0.2471, 0.2163, 0.1884, 0.1851],\n",
      "        [0.1607, 0.2234, 0.2369, 0.1790, 0.2000],\n",
      "        [0.1849, 0.2164, 0.2054, 0.1943, 0.1990],\n",
      "        [0.1866, 0.2091, 0.2478, 0.1913, 0.1651],\n",
      "        [0.1706, 0.2273, 0.2305, 0.1941, 0.1775],\n",
      "        [0.1843, 0.2126, 0.2056, 0.1781, 0.2193],\n",
      "        [0.1780, 0.2180, 0.2112, 0.1953, 0.1976],\n",
      "        [0.1723, 0.2233, 0.2149, 0.1814, 0.2080],\n",
      "        [0.1810, 0.2190, 0.2006, 0.2022, 0.1971],\n",
      "        [0.1810, 0.2226, 0.1962, 0.1977, 0.2026],\n",
      "        [0.1713, 0.2413, 0.2097, 0.1932, 0.1846],\n",
      "        [0.1742, 0.2087, 0.2159, 0.2019, 0.1994],\n",
      "        [0.1551, 0.2633, 0.2320, 0.1629, 0.1867],\n",
      "        [0.1676, 0.2168, 0.2137, 0.1874, 0.2144],\n",
      "        [0.1744, 0.2298, 0.2053, 0.2028, 0.1877],\n",
      "        [0.1731, 0.2174, 0.2061, 0.2113, 0.1920],\n",
      "        [0.1629, 0.2252, 0.2338, 0.2066, 0.1715],\n",
      "        [0.1688, 0.2185, 0.1980, 0.2170, 0.1978],\n",
      "        [0.1858, 0.2135, 0.2043, 0.2030, 0.1935],\n",
      "        [0.1930, 0.1897, 0.2215, 0.1964, 0.1995],\n",
      "        [0.1772, 0.2400, 0.2018, 0.1760, 0.2050],\n",
      "        [0.1614, 0.2494, 0.2113, 0.1945, 0.1834],\n",
      "        [0.1490, 0.2363, 0.2853, 0.1709, 0.1584],\n",
      "        [0.1542, 0.2324, 0.2461, 0.1841, 0.1832],\n",
      "        [0.1431, 0.2628, 0.2072, 0.1637, 0.2231]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ffn_hidden_units = 16\n",
    "n_hidden_layers = 2\n",
    "\n",
    "model = _ONNHBPModel(input_units=n_features,\n",
    "                     output_units=n_classes,\n",
    "                     hidden_units=ffn_hidden_units,\n",
    "                     n_hidden_layers=n_hidden_layers)\n",
    "\n",
    "output = model(X)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3. Check skorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3ab038f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.6667\u001b[0m  0.0189\n",
      "<class 'sail.models.torch.onn_hbp.ONNHBPClassifier'>[initialized](\n",
      "  module_=_ONNHBPModel(\n",
      "    (hidden_layers): ModuleList(\n",
      "      (0): Linear(in_features=15, out_features=16, bias=True)\n",
      "      (1): Linear(in_features=16, out_features=16, bias=True)\n",
      "    )\n",
      "    (output_layers): ModuleList(\n",
      "      (0-1): 2 x Linear(in_features=16, out_features=5, bias=True)\n",
      "    )\n",
      "    (do): Dropout(p=0.2, inplace=False)\n",
      "    (actfn): ReLU()\n",
      "  ),\n",
      ")\n",
      "[0 0 0 3 0 0 0 0 3 2 0 3 3 2 3 3 3 3 0 0 2 3 2 0 0 0 0 0 3 0 2 1 3 2 2 3 3\n",
      " 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "model_skorch = ONNHBPClassifier(input_units=n_features,\n",
    "                                 output_units=n_classes,\n",
    "                                 hidden_units=ffn_hidden_units,\n",
    "                                 n_hidden_layers=n_hidden_layers)\n",
    "\n",
    "partial_fit = model_skorch.partial_fit(X,y)\n",
    "print(partial_fit)\n",
    "predict = model_skorch.predict(X)\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d398e54",
   "metadata": {},
   "source": [
    "### 2. Load the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdbf8069",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "names = iris['target_names']\n",
    "feature_names = iris['feature_names']\n",
    "\n",
    "# Scale data to have mean 0 and variance 1\n",
    "# which is importance for convergence of the neural network\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data set into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c438a51",
   "metadata": {},
   "source": [
    "### 3. Train and test ONN on Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec8adb44",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.0647\u001b[0m  0.0039\n",
      "      2        \u001b[36m1.0629\u001b[0m  0.0069\n",
      "      3        \u001b[36m1.0606\u001b[0m  0.0062\n",
      "      4        \u001b[36m1.0583\u001b[0m  0.0070\n",
      "      5        \u001b[36m1.0560\u001b[0m  0.0062\n",
      "Accuracy on the test data 0.7\n"
     ]
    }
   ],
   "source": [
    "n_features = X_train.shape[1]\n",
    "n_classes = np.unique(y_test).shape[0]\n",
    "ffn_hidden_units = 50\n",
    "n_hidden_layers = 3\n",
    "\n",
    "model_skorch = ONNHBPClassifier(input_units=n_features,\n",
    "                                 output_units=n_classes,\n",
    "                                 hidden_units=ffn_hidden_units,\n",
    "                                 n_hidden_layers=n_hidden_layers)\n",
    "partial_fit = None\n",
    "for i in range(0,5):\n",
    "    partial_fit = model_skorch.partial_fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy on the test data', partial_fit.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 4. Mini-batch training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001b[36m1.1313\u001b[0m  0.0028\n",
      "      2        1.1428  0.0067\n",
      "      3        \u001b[36m1.1297\u001b[0m  0.0045\n",
      "      4        1.1298  0.0038\n",
      "      5        \u001b[36m1.1133\u001b[0m  0.0088\n",
      "      6        1.1667  0.0054\n",
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "\n",
    "model_skorch = ONNHBPClassifier(input_units=n_features,\n",
    "                                 output_units=n_classes,\n",
    "                                 hidden_units=ffn_hidden_units,\n",
    "                                 n_hidden_layers=n_hidden_layers)\n",
    "\n",
    "for batch in gen_batches(X_train.shape[0], batch_size):\n",
    "    x_batch = X_train[batch]\n",
    "    y_batch = y_train[batch]\n",
    "    partial_fit = model_skorch.partial_fit(x_batch, y_batch)\n",
    "\n",
    "predict = model_skorch.predict(X_test)\n",
    "\n",
    "print(partial_fit.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 5. Improving the results.\n",
    "Note, the results of doing mini batch learning are very bad. This is because we only do one single epoch. An easy way to improve this is by running partial fit for each mini-batch several times, i.e, multiple epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7        1.1206  0.0044\n",
      "      8        1.1451  0.0038\n",
      "      9        1.1512  0.0042\n",
      "     10        1.1198  0.0088\n",
      "     11        \u001b[36m1.1128\u001b[0m  0.0036\n",
      "     12        1.1842  0.0036\n",
      "     13        \u001b[36m1.0931\u001b[0m  0.0041\n",
      "     14        1.1110  0.0025\n",
      "     15        1.1176  0.0040\n",
      "     16        1.1296  0.0022\n",
      "     17        1.1264  0.0029\n",
      "     18        1.1322  0.0027\n",
      "     19        1.1195  0.0026\n",
      "     20        \u001b[36m1.0751\u001b[0m  0.0037\n",
      "     21        1.1132  0.0035\n",
      "     22        1.1027  0.0043\n",
      "     23        1.1161  0.0037\n",
      "     24        1.0928  0.0029\n",
      "     25        1.1117  0.0033\n",
      "     26        1.1075  0.0041\n",
      "     27        1.0975  0.0031\n",
      "     28        \u001b[36m1.0603\u001b[0m  0.0025\n",
      "     29        1.0973  0.0039\n",
      "     30        1.0699  0.0033\n",
      "     31        \u001b[36m1.0593\u001b[0m  0.0038\n",
      "     32        1.0922  0.0035\n",
      "     33        1.0774  0.0036\n",
      "     34        1.0789  0.0033\n",
      "     35        \u001b[36m1.0591\u001b[0m  0.0025\n",
      "     36        1.0739  0.0039\n",
      "     37        1.1004  0.0023\n",
      "     38        1.0769  0.0029\n",
      "     39        \u001b[36m1.0491\u001b[0m  0.0041\n",
      "     40        1.0847  0.0024\n",
      "     41        1.0696  0.0035\n",
      "     42        1.0532  0.0032\n",
      "     43        \u001b[36m1.0433\u001b[0m  0.0034\n",
      "     44        1.0733  0.0031\n",
      "     45        1.0747  0.0043\n",
      "     46        1.0480  0.0038\n",
      "     47        \u001b[36m1.0402\u001b[0m  0.0042\n",
      "     48        1.0513  0.0044\n",
      "     49        1.0639  0.0044\n",
      "     50        1.0615  0.0026\n",
      "     51        1.0479  0.0052\n",
      "     52        1.0829  0.0020\n",
      "     53        1.0413  0.0026\n",
      "     54        1.0436  0.0046\n",
      "     55        1.0481  0.0036\n",
      "     56        1.0499  0.0034\n",
      "     57        1.0448  0.0054\n",
      "     58        \u001b[36m1.0165\u001b[0m  0.0042\n",
      "     59        1.0406  0.0042\n",
      "     60        1.0474  0.0077\n",
      "     61        1.0252  0.0045\n",
      "     62        1.0391  0.0111\n",
      "     63        1.0622  0.0065\n",
      "     64        1.0249  0.0050\n",
      "     65        1.0436  0.0048\n",
      "     66        1.0334  0.0045\n",
      "Accuracy after 10 epochs 0.7666666666666667\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10): # n_epochs\n",
    "    for batch in gen_batches(X_train.shape[0], batch_size):\n",
    "        x_batch = X_train[batch]\n",
    "        y_batch = y_train[batch]\n",
    "        partial_fit = model_skorch.partial_fit(x_batch, y_batch)\n",
    "        # Shuffling the dataset\n",
    "        permutation = torch.randperm(X_train.shape[0])\n",
    "        X_train = X_train[permutation]\n",
    "        y_train = y_train[permutation]\n",
    "\n",
    "# Note how the results improved considerably\n",
    "print('Accuracy after 10 epochs', partial_fit.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training and testing simultaneously, one example at the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Online Accuracy at time 0/3500: 0.07666666666666666\n",
      "Online Accuracy at time 1000/3500: 0.9693333333333334\n",
      "Online Accuracy at time 2000/3500: 0.9633333333333334\n",
      "Online Accuracy at time 3000/3500: 0.9766666666666667\n",
      "Training and testing finished.\n",
      "Final accuracy after 3500 samples: 0.97\n"
     ]
    }
   ],
   "source": [
    "X, Y = make_classification(n_samples=5000, n_features=10, n_informative=4, n_redundant=0, n_classes=10,\n",
    "                           n_clusters_per_class=1, class_sep=3)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "onn_network = ONNHBPClassifier(input_units=10,\n",
    "                                output_units=10,\n",
    "                                hidden_units=40,\n",
    "                                n_hidden_layers=5,\n",
    "                                train_split=None,\n",
    "                                verbose=0\n",
    "                                )\n",
    "\n",
    "n_training_samples = len(X_train)\n",
    "for i in range(n_training_samples):\n",
    "  partial_fit = onn_network.partial_fit(np.asarray([X_train[i, :]]), np.asarray([y_train[i]]))\n",
    "\n",
    "  if i % 1000 == 0:\n",
    "    print(\"Online Accuracy at time {}/{}: {}\".format(i, n_training_samples, partial_fit.score(X_test, y_test)))\n",
    "\n",
    "print('Training and testing finished.\\nFinal accuracy after {} samples: {}'.format(n_training_samples, partial_fit.score(X_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-sail",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
