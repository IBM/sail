{"cells":[{"cell_type":"markdown","metadata":{"id":"4aWn-DaOwR9V"},"source":["This notebook shows the implementation of a skorch wrapper class containing the InceptionTime model. Code for the model itself was based on https://github.com/okrasolar/pytorch-timeseries\n","\n","Author: Christos C. Papadopoulos\n","https://github.com/Christosc96"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":501,"status":"ok","timestamp":1653691702245,"user":{"displayName":"Christos Papadopoulos","userId":"08141375972921064188"},"user_tz":-180},"id":"mwZxjz7lvNS_"},"outputs":[],"source":["\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","\n","from sklearn.datasets import make_classification\n","from sklearn.preprocessing import MinMaxScaler\n","import numpy as np\n","\n","\n","from typing import cast, Union, List\n","from skorch import NeuralNetClassifier"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":215,"status":"ok","timestamp":1653691705256,"user":{"displayName":"Christos Papadopoulos","userId":"08141375972921064188"},"user_tz":-180},"id":"BexVwE0lxxBw"},"outputs":[],"source":["'''\n","Define conv1d with same padding\n","'''\n","\n","\n","\n","class Conv1dSamePadding(nn.Conv1d):\n","    \"\"\"Represents the \"Same\" padding functionality from Tensorflow.\n","    See: https://github.com/pytorch/pytorch/issues/3867\n","    Note that the padding argument in the initializer doesn't do anything now\n","    \"\"\"\n","    def forward(self, input):\n","        return conv1d_same_padding(input, self.weight, self.bias, self.stride,\n","                                   self.dilation, self.groups)\n","\n","\n","def conv1d_same_padding(input, weight, bias, stride, dilation, groups):\n","    # stride and dilation are expected to be tuples.\n","    kernel, dilation, stride = weight.size(2), dilation[0], stride[0]\n","    l_out = l_in = input.size(2)\n","    padding = (((l_out - 1) * stride) - l_in + (dilation * (kernel - 1)) + 1)\n","    if padding % 2 != 0:\n","        input = F.pad(input, [0, 1])\n","\n","    return F.conv1d(input=input, weight=weight, bias=bias, stride=stride,\n","                    padding=padding // 2,\n","                    dilation=dilation, groups=groups)\n","\n","\n","class ConvBlock(nn.Module):\n","\n","    def __init__(self, in_channels: int, out_channels: int, kernel_size: int,\n","                 stride: int) -> None:\n","        super().__init__()\n","\n","        self.layers = nn.Sequential(\n","            Conv1dSamePadding(in_channels=in_channels,\n","                              out_channels=out_channels,\n","                              kernel_size=kernel_size,\n","                              stride=stride),\n","            nn.BatchNorm1d(num_features=out_channels),\n","            nn.ReLU(),\n","        )\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:  # type: ignore\n","\n","        return self.layers(x)"]},{"cell_type":"markdown","metadata":{"id":"GKaoP2_BFwIL"},"source":["Define the _InceptionModel class. Code is based on https://github.com/okrasolar/pytorch-timeseries"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":476,"status":"ok","timestamp":1653691706909,"user":{"displayName":"Christos Papadopoulos","userId":"08141375972921064188"},"user_tz":-180},"id":"QwPIUQoDxGiR"},"outputs":[],"source":["class _InceptionModel(nn.Module):\n","    \"\"\"A PyTorch implementation of the InceptionTime model.\n","    From https://arxiv.org/abs/1909.04939\n","    Attributes\n","    ----------\n","    num_blocks:\n","        The number of inception blocks to use. One inception block consists\n","        of 3 convolutional layers, (optionally) a bottleneck and (optionally) a residual\n","        connector\n","    in_channels:\n","        The number of input channels (i.e. input.shape[-1])\n","    out_channels:\n","        The number of \"hidden channels\" to use. Can be a list (for each block) or an\n","        int, in which case the same value will be applied to each block\n","    bottleneck_channels:\n","        The number of channels to use for the bottleneck. Can be list or int. If 0, no\n","        bottleneck is applied\n","    kernel_sizes:\n","        The size of the kernels to use for each inception block. Within each block, each\n","        of the 3 convolutional layers will have kernel size\n","        `[kernel_size // (2 ** i) for i in range(3)]`\n","    num_pred_classes:\n","        The number of output classes\n","    \"\"\"\n","\n","    def __init__(self, num_blocks: int, in_channels: int, out_channels: Union[List[int], int],\n","                 bottleneck_channels: Union[List[int], int], kernel_sizes: Union[List[int], int],\n","                 use_residuals: Union[List[bool], bool, str] = 'default',\n","                 num_pred_classes: int = 1\n","                 ) -> None:\n","        super().__init__()\n","\n","        # for easier saving and loading\n","        self.input_args = {\n","            'num_blocks': num_blocks,\n","            'in_channels': in_channels,\n","            'out_channels': out_channels,\n","            'bottleneck_channels': bottleneck_channels,\n","            'kernel_sizes': kernel_sizes,\n","            'use_residuals': use_residuals,\n","            'num_pred_classes': num_pred_classes\n","        }\n","\n","        channels = [in_channels] + cast(List[int], self._expand_to_blocks(out_channels,\n","                                                                          num_blocks))\n","        bottleneck_channels = cast(List[int], self._expand_to_blocks(bottleneck_channels,\n","                                                                     num_blocks))\n","        kernel_sizes = cast(List[int], self._expand_to_blocks(kernel_sizes, num_blocks))\n","        if use_residuals == 'default':\n","            use_residuals = [True if i % 3 == 2 else False for i in range(num_blocks)]\n","        use_residuals = cast(List[bool], self._expand_to_blocks(\n","            cast(Union[bool, List[bool]], use_residuals), num_blocks)\n","        )\n","\n","        self.blocks = nn.Sequential(*[\n","            _InceptionBlock(in_channels=channels[i], out_channels=channels[i + 1],\n","                           residual=use_residuals[i], bottleneck_channels=bottleneck_channels[i],\n","                           kernel_size=kernel_sizes[i]) for i in range(num_blocks)\n","        ])\n","\n","        # a global average pooling (i.e. mean of the time dimension) is why\n","        # in_features=channels[-1]\n","        self.linear = nn.Linear(in_features=channels[-1], out_features=num_pred_classes)\n","\n","    @staticmethod\n","    def _expand_to_blocks(value: Union[int, bool, List[int], List[bool]],\n","                          num_blocks: int) -> Union[List[int], List[bool]]:\n","        if isinstance(value, list):\n","            assert len(value) == num_blocks, \\\n","                f'Length of inputs lists must be the same as num blocks, ' \\\n","                f'expected length {num_blocks}, got {len(value)}'\n","        else:\n","            value = [value] * num_blocks\n","        return value\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:  # type: ignore\n","        x = self.blocks(x).mean(dim=-1)  # the mean is the global average pooling\n","        return self.linear(x)\n","\n","\n","class _InceptionBlock(nn.Module):\n","    \"\"\"An inception block consists of an (optional) bottleneck, followed\n","    by 3 conv1d layers. Optionally residual\n","    \"\"\"\n","\n","    def __init__(self, in_channels: int, out_channels: int,\n","                 residual: bool, stride: int = 1, bottleneck_channels: int = 32,\n","                 kernel_size: int = 41) -> None:\n","        assert kernel_size > 3, \"Kernel size must be strictly greater than 3\"\n","        super().__init__()\n","\n","        self.use_bottleneck = bottleneck_channels > 0\n","        if self.use_bottleneck:\n","            self.bottleneck = Conv1dSamePadding(in_channels, bottleneck_channels,\n","                                                kernel_size=1, bias=False)\n","        kernel_size_s = [kernel_size // (2 ** i) for i in range(3)]\n","        start_channels = bottleneck_channels if self.use_bottleneck else in_channels\n","        channels = [start_channels] + [out_channels] * 3\n","        self.conv_layers = nn.Sequential(*[\n","            Conv1dSamePadding(in_channels=channels[i], out_channels=channels[i + 1],\n","                              kernel_size=kernel_size_s[i], stride=stride, bias=False)\n","            for i in range(len(kernel_size_s))\n","        ])\n","\n","        self.batchnorm = nn.BatchNorm1d(num_features=channels[-1])\n","        self.relu = nn.ReLU()\n","\n","        self.use_residual = residual\n","        if residual:\n","            self.residual = nn.Sequential(*[\n","                Conv1dSamePadding(in_channels=in_channels, out_channels=out_channels,\n","                                  kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm1d(out_channels),\n","                nn.ReLU()\n","            ])\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:  # type: ignore\n","        org_x = x\n","        if self.use_bottleneck:\n","            x = self.bottleneck(x)\n","        x = self.conv_layers(x)\n","\n","        if self.use_residual:\n","            x = x + self.residual(org_x)\n","        return x"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":396,"status":"ok","timestamp":1653691710182,"user":{"displayName":"Christos Papadopoulos","userId":"08141375972921064188"},"user_tz":-180},"id":"tpTQ1NKnyzOu"},"outputs":[],"source":["'''\n","wrapper scorch class\n","'''\n","\n","\n","class InceptionTimeClassifier(NeuralNetClassifier):\n","  def __init__(self, num_blocks=2, in_channels=1, out_channels=2,\n","                           bottleneck_channels=2, kernel_sizes=41, use_residuals=True,\n","                           num_pred_classes=1, learning_rate=0.05, batch_size=1000, criterion = nn.BCEWithLogitsLoss, max_epochs = 50):\n","    \n","    self.inception_model = _InceptionModel(num_blocks=2, in_channels=1, out_channels=2,\n","                           bottleneck_channels=2, kernel_sizes=41, use_residuals=True,\n","                           num_pred_classes=1)\n","    \n","    super(InceptionTimeClassifier, self).__init__(\n","            module=self.inception_model,\n","            max_epochs=max_epochs,\n","            lr=learning_rate,\n","            batch_size=batch_size,\n","            criterion=criterion ,\n","            # Shuffle training data on each epoch\n","            iterator_train__shuffle=False,\n","            device='cpu',\n","            )"]},{"cell_type":"markdown","metadata":{"id":"TD7Lf8xSFIWk"},"source":["Generate data for training the model. The data used originates from the FordA dataset which is included in the InceptionTime paper as well"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":2644,"status":"ok","timestamp":1653691715847,"user":{"displayName":"Christos Papadopoulos","userId":"08141375972921064188"},"user_tz":-180},"id":"vjUwoPR2c9JJ"},"outputs":[],"source":["def readucr(filename):\n","    data = np.loadtxt(filename, delimiter=\"\\t\")\n","    y = data[:, 0]\n","    x = data[:, 1:]\n","    return x, y.astype(int)\n","\n","\n","root_url = \"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/\"\n","\n","x_train, y_train = readucr(root_url + \"FordA_TRAIN.tsv\")\n","x_test, y_test = readucr(root_url + \"FordA_TEST.tsv\")\n","\n","x_train = x_train.reshape((x_train.shape[0], 1, x_train.shape[1], ))\n","x_test = x_test.reshape((x_test.shape[0], 1, x_test.shape[1]))\n","y_train[y_train == -1] = 0\n","y_test[y_test == -1] = 0\n","x_train = torch.from_numpy(x_train)\n","y_train = torch.from_numpy(y_train)\n","y_train=y_train.unsqueeze(1)\n","\n","x_train=x_train.to(torch.float32)\n","y_train=y_train.to(torch.float32)"]},{"cell_type":"markdown","metadata":{"id":"Jh9x3fsTFaUR"},"source":["To train the model, since we are using a Scorch wrapper, simply call fit after creating it. "]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1912,"status":"ok","timestamp":1653691950777,"user":{"displayName":"Christos Papadopoulos","userId":"08141375972921064188"},"user_tz":-180},"id":"EeerDclv6B5D","outputId":"0a15b5fb-8ca0-490d-baf6-35e3d4f7f878"},"outputs":[{"name":"stdout","output_type":"stream","text":["  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m0.6930\u001b[0m       \u001b[32m0.5132\u001b[0m        \u001b[35m0.6928\u001b[0m  0.9276\n","      2        \u001b[36m0.6929\u001b[0m       0.5132        \u001b[35m0.6928\u001b[0m  0.6998\n","      3        \u001b[36m0.6929\u001b[0m       0.5132        \u001b[35m0.6928\u001b[0m  0.7904\n","      4        \u001b[36m0.6929\u001b[0m       0.5132        \u001b[35m0.6928\u001b[0m  0.6708\n","      5        \u001b[36m0.6929\u001b[0m       0.5132        \u001b[35m0.6928\u001b[0m  0.6715\n","      6        \u001b[36m0.6929\u001b[0m       0.5132        \u001b[35m0.6928\u001b[0m  0.6734\n","      7        \u001b[36m0.6929\u001b[0m       0.5132        \u001b[35m0.6928\u001b[0m  0.6614\n","      8        \u001b[36m0.6929\u001b[0m       0.5132        \u001b[35m0.6928\u001b[0m  0.6776\n","      9        \u001b[36m0.6929\u001b[0m       0.5132        \u001b[35m0.6928\u001b[0m  0.6674\n","     10        \u001b[36m0.6928\u001b[0m       0.5132        \u001b[35m0.6928\u001b[0m  0.6759\n","     11        \u001b[36m0.6928\u001b[0m       0.5132        \u001b[35m0.6928\u001b[0m  0.6947\n","     12        \u001b[36m0.6928\u001b[0m       0.5132        \u001b[35m0.6927\u001b[0m  0.7640\n","     13        \u001b[36m0.6928\u001b[0m       0.5132        \u001b[35m0.6927\u001b[0m  0.9475\n","     14        \u001b[36m0.6928\u001b[0m       0.5132        \u001b[35m0.6927\u001b[0m  0.8065\n","     15        \u001b[36m0.6928\u001b[0m       0.5132        \u001b[35m0.6927\u001b[0m  0.6981\n","     16        \u001b[36m0.6928\u001b[0m       0.5132        \u001b[35m0.6927\u001b[0m  0.7554\n","     17        \u001b[36m0.6928\u001b[0m       0.5132        \u001b[35m0.6927\u001b[0m  0.6869\n","     18        \u001b[36m0.6928\u001b[0m       0.5132        \u001b[35m0.6927\u001b[0m  0.6932\n","     19        \u001b[36m0.6928\u001b[0m       0.5132        \u001b[35m0.6927\u001b[0m  0.7028\n","     20        \u001b[36m0.6928\u001b[0m       0.5132        \u001b[35m0.6927\u001b[0m  1.3248\n"]},{"data":{"text/plain":["<class '__main__.InceptionTimeClassifier'>[initialized](\n","  module_=_InceptionModel(\n","    (blocks): Sequential(\n","      (0): _InceptionBlock(\n","        (bottleneck): Conv1dSamePadding(1, 2, kernel_size=(1,), stride=(1,), bias=False)\n","        (conv_layers): Sequential(\n","          (0): Conv1dSamePadding(2, 2, kernel_size=(41,), stride=(1,), bias=False)\n","          (1): Conv1dSamePadding(2, 2, kernel_size=(20,), stride=(1,), bias=False)\n","          (2): Conv1dSamePadding(2, 2, kernel_size=(10,), stride=(1,), bias=False)\n","        )\n","        (batchnorm): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","        (residual): Sequential(\n","          (0): Conv1dSamePadding(1, 2, kernel_size=(1,), stride=(1,), bias=False)\n","          (1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU()\n","        )\n","      )\n","      (1): _InceptionBlock(\n","        (bottleneck): Conv1dSamePadding(2, 2, kernel_size=(1,), stride=(1,), bias=False)\n","        (conv_layers): Sequential(\n","          (0): Conv1dSamePadding(2, 2, kernel_size=(41,), stride=(1,), bias=False)\n","          (1): Conv1dSamePadding(2, 2, kernel_size=(20,), stride=(1,), bias=False)\n","          (2): Conv1dSamePadding(2, 2, kernel_size=(10,), stride=(1,), bias=False)\n","        )\n","        (batchnorm): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU()\n","        (residual): Sequential(\n","          (0): Conv1dSamePadding(2, 2, kernel_size=(1,), stride=(1,), bias=False)\n","          (1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU()\n","        )\n","      )\n","    )\n","    (linear): Linear(in_features=2, out_features=1, bias=True)\n","  ),\n",")"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["model = InceptionTimeClassifier(out_channels=10, bottleneck_channels=10, batch_size=500, max_epochs=20, learning_rate=0.5)\n","model.fit(x_train, y_train)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOF8JT6xpITNRmcL+IM9TAI","name":"InceptionTime.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}
