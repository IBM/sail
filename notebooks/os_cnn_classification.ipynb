{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f371e50e-fb5c-4f5f-a39a-4258b7deb6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from os.path import dirname\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sail.models.torch.os_cnn import OS_CNN_CLassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17fb7c93-7d34-4587-b7e2-89ad6f20cb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# methods for preprocessing data \n",
    "def set_nan_to_zero(a):\n",
    "    where_are_NaNs = np.isnan(a)\n",
    "    a[where_are_NaNs] = 0\n",
    "    return a\n",
    "\n",
    "def TSC_data_loader(dataset_path,dataset_name):\n",
    "    Train_dataset = np.loadtxt(\n",
    "        dataset_path + '/' + dataset_name + '/' + dataset_name + '_TRAIN.tsv')\n",
    "    Test_dataset = np.loadtxt(\n",
    "        dataset_path + '/' + dataset_name + '/' + dataset_name + '_TEST.tsv')\n",
    "    Train_dataset = Train_dataset.astype(np.float32)\n",
    "    Test_dataset = Test_dataset.astype(np.float32)\n",
    "\n",
    "    X_train = Train_dataset[:, 1:]\n",
    "    y_train = Train_dataset[:, 0:1]\n",
    "\n",
    "    X_test = Test_dataset[:, 1:]\n",
    "    y_test = Test_dataset[:, 0:1]\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(np.squeeze(y_train, axis=1))\n",
    "    y_train = le.transform(np.squeeze(y_train, axis=1))\n",
    "    y_test = le.transform(np.squeeze(y_test, axis=1))\n",
    "    return set_nan_to_zero(X_train), y_train, set_nan_to_zero(X_test), y_test\n",
    "\n",
    "\n",
    "def load_to_torch(X_train, y_train, X_test, y_test, device):\n",
    "    X_train = torch.from_numpy(X_train)\n",
    "    X_train.requires_grad = False\n",
    "    X_train = X_train.to(device)\n",
    "    y_train = torch.from_numpy(y_train).to(device)\n",
    "\n",
    "    X_test = torch.from_numpy(X_test)\n",
    "    X_test.requires_grad = False\n",
    "    X_test = X_test.to(device)\n",
    "    y_test = torch.from_numpy(y_test).to(device)\n",
    "\n",
    "\n",
    "    if len(X_train.shape) == 2:\n",
    "        X_train = X_train.unsqueeze_(1)\n",
    "        X_test = X_test.unsqueeze_(1)\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a299d4e",
   "metadata": {},
   "source": [
    "##### Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdf62c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/dhaval/Projects/MORE/sail-version-bump/notebooks/UCRArchive_2018/FiftyWords/desktop.ini',\n",
       " '/Users/dhaval/Projects/MORE/sail-version-bump/notebooks/UCRArchive_2018/FiftyWords/FiftyWords_TEST.tsv',\n",
       " '/Users/dhaval/Projects/MORE/sail-version-bump/notebooks/UCRArchive_2018/FiftyWords/FiftyWords_TRAIN.tsv',\n",
       " '/Users/dhaval/Projects/MORE/sail-version-bump/notebooks/UCRArchive_2018/FiftyWords/README.md']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "url = \"https://drive.google.com/drive/folders/1SyX8ylC6TbwJPnLKPP_o4qdm03r-0Yby\"\n",
    "gdown.download_folder(url, quiet=True, use_cookies=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e80cc71e-edc6-4df2-917f-bfa20f20d004",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TSC_data_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m dataset_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mFiftyWords\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[39m# load data,\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m X_train, y_train, X_test, y_test \u001b[39m=\u001b[39m TSC_data_loader(dataset_path, dataset_name)\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtrain data shape\u001b[39m\u001b[39m'\u001b[39m, X_train\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TSC_data_loader' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_path = \"UCRArchive_2018\"\n",
    "dataset_name = \"FiftyWords\"\n",
    "\n",
    "# load data,\n",
    "X_train, y_train, X_test, y_test = TSC_data_loader(dataset_path, dataset_name)\n",
    "print('train data shape', X_train.shape)\n",
    "print()\n",
    "print('train label shape',y_train.shape)\n",
    "print('test data shape',X_test.shape)\n",
    "print('test label shape',y_test.shape)\n",
    "print('unique train label',np.unique(y_train))\n",
    "print('unique test label',np.unique(y_test))\n",
    "device = \"cpu\"\n",
    "X_train, y_train, X_test, y_test = load_to_torch(X_train, y_train, X_test, y_test, device)\n",
    "\n",
    "# the model prints out the result every epoch\n",
    "# defaul epoch size = 20\n",
    "Max_kernel_size = 89\n",
    "start_kernel_size = 1\n",
    "# loss, optimizer, scheduler\n",
    "input_channel = X_train.shape[1] # input channel size\n",
    "n_class = max(y_train) + 1 # output class number\n",
    "receptive_field_shape= min(int(X_train.shape[-1]/4),Max_kernel_size)\n",
    "\n",
    "model = OS_CNN_CLassifier(n_class.item(), input_channel, receptive_field_shape)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17a15659-94d5-424c-9d64-7fb3dd2ed3b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6791208791208792"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "N_test=X_test.shape[0]\n",
    "yhat = model.predict(X_test)\n",
    "correct += (torch.tensor(yhat) == y_test).sum().item()\n",
    "accuracy = correct / N_test\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
