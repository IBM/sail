{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f371e50e-fb5c-4f5f-a39a-4258b7deb6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abduvoris/anaconda3/envs/imla_assignment/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "\n",
    "from os.path import dirname\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sail.models.torch.os_cnn import OS_CNN_CLassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17fb7c93-7d34-4587-b7e2-89ad6f20cb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_nan_to_zero(a):\n",
    "    where_are_NaNs = np.isnan(a)\n",
    "    a[where_are_NaNs] = 0\n",
    "    return a\n",
    "\n",
    "def TSC_data_loader(dataset_path,dataset_name):\n",
    "    Train_dataset = np.loadtxt(\n",
    "        dataset_path + '/' + dataset_name + '/' + dataset_name + '_TRAIN.tsv')\n",
    "    Test_dataset = np.loadtxt(\n",
    "        dataset_path + '/' + dataset_name + '/' + dataset_name + '_TEST.tsv')\n",
    "    Train_dataset = Train_dataset.astype(np.float32)\n",
    "    Test_dataset = Test_dataset.astype(np.float32)\n",
    "\n",
    "    X_train = Train_dataset[:, 1:]\n",
    "    y_train = Train_dataset[:, 0:1]\n",
    "\n",
    "    X_test = Test_dataset[:, 1:]\n",
    "    y_test = Test_dataset[:, 0:1]\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(np.squeeze(y_train, axis=1))\n",
    "    y_train = le.transform(np.squeeze(y_train, axis=1))\n",
    "    y_test = le.transform(np.squeeze(y_test, axis=1))\n",
    "    return set_nan_to_zero(X_train), y_train, set_nan_to_zero(X_test), y_test\n",
    "\n",
    "\n",
    "def load_to_torch(X_train, y_train, X_test, y_test, device):\n",
    "    X_train = torch.from_numpy(X_train)\n",
    "    X_train.requires_grad = False\n",
    "    X_train = X_train.to(device)\n",
    "    y_train = torch.from_numpy(y_train).to(device)\n",
    "\n",
    "    X_test = torch.from_numpy(X_test)\n",
    "    X_test.requires_grad = False\n",
    "    X_test = X_test.to(device)\n",
    "    y_test = torch.from_numpy(y_test).to(device)\n",
    "\n",
    "\n",
    "    if len(X_train.shape) == 2:\n",
    "        X_train = X_train.unsqueeze_(1)\n",
    "        X_test = X_test.unsqueeze_(1)\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e80cc71e-edc6-4df2-917f-bfa20f20d004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape (450, 270)\n",
      "\n",
      "train label shape (450,)\n",
      "test data shape (455, 270)\n",
      "test label shape (455,)\n",
      "unique train label [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "unique test label [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abduvoris/anaconda3/envs/imla_assignment/lib/python3.9/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m3.6838\u001b[0m       \u001b[32m0.2222\u001b[0m        \u001b[35m3.2757\u001b[0m  1.5532\n",
      "      2        \u001b[36m3.1325\u001b[0m       0.2222        \u001b[35m2.9934\u001b[0m  1.6128\n",
      "      3        \u001b[36m2.8331\u001b[0m       \u001b[32m0.2444\u001b[0m        \u001b[35m2.6731\u001b[0m  1.5441\n",
      "      4        \u001b[36m2.5332\u001b[0m       \u001b[32m0.3444\u001b[0m        \u001b[35m2.4476\u001b[0m  1.5825\n",
      "      5        \u001b[36m2.2659\u001b[0m       0.3111        \u001b[35m2.3056\u001b[0m  1.5683\n",
      "      6        \u001b[36m2.0388\u001b[0m       \u001b[32m0.4111\u001b[0m        \u001b[35m1.9912\u001b[0m  1.5885\n",
      "      7        \u001b[36m1.8238\u001b[0m       \u001b[32m0.5333\u001b[0m        \u001b[35m1.8264\u001b[0m  1.7760\n",
      "      8        \u001b[36m1.6135\u001b[0m       0.5222        \u001b[35m1.7733\u001b[0m  1.7264\n",
      "      9        \u001b[36m1.4831\u001b[0m       \u001b[32m0.6333\u001b[0m        \u001b[35m1.5817\u001b[0m  1.6401\n",
      "     10        \u001b[36m1.3077\u001b[0m       0.5667        1.6581  1.6337\n",
      "     11        \u001b[36m1.1867\u001b[0m       0.5778        1.7216  1.5677\n",
      "     12        \u001b[36m1.0624\u001b[0m       0.5889        \u001b[35m1.5658\u001b[0m  1.5669\n",
      "     13        \u001b[36m0.8965\u001b[0m       0.6000        \u001b[35m1.3917\u001b[0m  1.6197\n",
      "     14        \u001b[36m0.7146\u001b[0m       0.6222        1.4322  1.7137\n",
      "     15        \u001b[36m0.5869\u001b[0m       0.6333        1.4565  1.7100\n",
      "     16        \u001b[36m0.4583\u001b[0m       \u001b[32m0.6778\u001b[0m        1.4137  2.0952\n",
      "     17        \u001b[36m0.3477\u001b[0m       \u001b[32m0.7000\u001b[0m        \u001b[35m1.3729\u001b[0m  1.9617\n",
      "     18        \u001b[36m0.2638\u001b[0m       \u001b[32m0.7222\u001b[0m        \u001b[35m1.3399\u001b[0m  1.9734\n",
      "     19        \u001b[36m0.2173\u001b[0m       \u001b[32m0.7444\u001b[0m        \u001b[35m1.2382\u001b[0m  2.5323\n",
      "     20        \u001b[36m0.1687\u001b[0m       0.6778        1.2843  2.0032\n"
     ]
    }
   ],
   "source": [
    "dataset_path = dirname(\"./notebooks/OS_CNN/UCRArchive_2018/\")\n",
    "dataset_name = \"FiftyWords\"\n",
    "\n",
    "# load data,\n",
    "X_train, y_train, X_test, y_test = TSC_data_loader(dataset_path, dataset_name)\n",
    "print('train data shape', X_train.shape)\n",
    "print()\n",
    "print('train label shape',y_train.shape)\n",
    "print('test data shape',X_test.shape)\n",
    "print('test label shape',y_test.shape)\n",
    "print('unique train label',np.unique(y_train))\n",
    "print('unique test label',np.unique(y_test))\n",
    "device = \"cpu\"\n",
    "X_train, y_train, X_test, y_test = load_to_torch(X_train, y_train, X_test, y_test, device)\n",
    "\n",
    "Max_kernel_size = 89\n",
    "start_kernel_size = 1\n",
    "input_channel = X_train.shape[1] # input channel size\n",
    "n_class = max(y_train) + 1 # output class number\n",
    "receptive_field_shape= min(int(X_train.shape[-1]/4),Max_kernel_size) # receptive fields\n",
    "\n",
    "model = OS_CNN_CLassifier(n_class.item(), input_channel, receptive_field_shape)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "batch_size = 16\n",
    "N_test=len(test_dataset)\n",
    "train_loader = DataLoader(train_dataset, batch_size=max(int(min(X_train.shape[0] / 10, batch_size)),2), shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=max(int(min(X_train.shape[0] / 10, batch_size)),2), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17a15659-94d5-424c-9d64-7fb3dd2ed3b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7164835164835165"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_list=[]\n",
    "correct = 0\n",
    "N_test=len(test_dataset)\n",
    "yhat = model.predict(X_test)\n",
    "correct += (torch.tensor(yhat) == y_test).sum().item()\n",
    "accuracy = correct / N_test\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f21f881-675d-493d-b61f-e555efa1e6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # partial fit\n",
    "\n",
    "# cnt = 0\n",
    "# wait_samples = 10 \n",
    "\n",
    "\n",
    "# model = OS_CNN_CLassifier(n_class.item(), input_channel, receptive_field_shape)\n",
    "\n",
    "# for sample in train_loader:\n",
    "\n",
    "\n",
    "#     model.partial_fit(sample[0], sample[1])\n",
    "#     y_hat = model.predict\n",
    "\n",
    "\n",
    "#     # Test every n samples\n",
    "#     if (cnt % wait_samples == 0) & (cnt != 0):\n",
    "#         model\n",
    "#     y_predict = model(sample[0]) # prediction\n",
    "#     output = lossfunc(y_predict, sample[1]) # calculate loss\n",
    "#     output.backward() # backpropagation, compute gradients\n",
    "#     optimizer.step() # apply gradients\n",
    "#     COST += output.data\n",
    "\n",
    "# #     cost_list.append(COST)\n",
    "# #     correct = 0\n",
    "# #     scheduler.step(output)\n",
    "# #     # perform prediction on the validation set\n",
    "# #     for x_test, y_test in test_loader:\n",
    "# #         z = model(x_test)\n",
    "# #         _, yhat = torch.max(z.data, 1)\n",
    "# #         correct += (yhat == y_test).sum().item()\n",
    "# #     accuracy = correct / N_test\n",
    "# #     accuracy_list.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61ff249b-d48a-4106-9409-6359c7569033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the loss and accuracy\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# fig, ax1 = plt.subplots()\n",
    "# color = 'tab:red'\n",
    "# ax1.plot(cost_list, color=color)\n",
    "# ax1.set_xlabel('epoch', color=color)\n",
    "# ax1.set_ylabel('Cost', color=color)\n",
    "# ax1.tick_params(axis='y', color=color)\n",
    "    \n",
    "# ax2 = ax1.twinx()  \n",
    "# color = 'tab:blue'\n",
    "# ax2.set_ylabel('accuracy', color=color) \n",
    "# ax2.set_xlabel('epoch', color=color)\n",
    "# ax2.plot( accuracy_list, color=color)\n",
    "# ax2.tick_params(axis='y', color=color)\n",
    "# fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8d3213-c627-4580-a64d-d08eab9cb015",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
